use log::debug;
use std::marker::PhantomData;
use std::sync::Arc;
use std::time::Duration;

use tls_api_openssl::TlsConnector;
use tokio::time::sleep;
use tor_rtcompat::PreferredRuntime;

use crate::errors;
use crate::request;

use crate::dispatcher::Dispatcher;
use crate::task::Task;

/// Each `Circuit` stores a Tor client which handles `Tasks`.
#[derive(Clone)]
pub struct Circuit<D: Dispatcher<T>, T: Task> {
    /// Used for logging purposes.
    worker: usize,
    /// The tor client
    client: hyper::Client<arti_hyper::ArtiHttpConnector<PreferredRuntime, TlsConnector>>,
    /// User defined dispatcher which implements the `Dispatcher` trait and returns structs that
    /// implement the `Task` trait.
    task_dispatcher: Arc<D>,
    /// How long to sleep between tasks
    task_buffer: f32,
    /// How long to sleep if there are no tasks (since each `Circuit` has an infinite loop).
    no_task_sleep: f32,
    task_phantom: PhantomData<T>,
}

/// Each `Circuit` is generated by the `CircuitHandler`.
impl<D, T> Circuit<D, T>
where
    D: Dispatcher<T>,
    T: Task,
{
    pub fn new(
        worker: usize,
        client: hyper::Client<arti_hyper::ArtiHttpConnector<PreferredRuntime, TlsConnector>>,
        task_dispatcher: Arc<D>,
        task_buffer: f32,
        no_task_sleep: f32,
    ) -> Circuit<D, T> {
        debug!("[worker={}] Created new circuit", worker);
        Circuit {
            worker,
            client,
            task_dispatcher,
            task_phantom: PhantomData,
            task_buffer,
            no_task_sleep,
        }
    }

    // TODO: Move WebArchive requests to a self-contained struct, instead of having individual functions using a RequestType enum.
    // TODO: Remove RequestType enum entirely.
    pub async fn run(&self) {
        debug!("[worker={}] Running", self.worker);
        loop {
            match self.task_dispatcher.get_task() {
                Some(mut task) => {
                    let request = task.get_request();
                    let response = match request.get_next_attempt() {
                        request::RequestType::Standard => {
                            debug!("[worker={}] request.next_attempt = Standard", self.worker);
                            request.inc_try();
                            self.execute_request(&request).await
                        }
                        request::RequestType::WebArchive => {
                            debug!("[worker={}] request.next_attempt = WebArchive", self.worker);
                            request.inc_try();
                            self.execute_webarchive_requests(&request).await
                        }
                        request::RequestType::Ignore => {
                            debug!("[worker={}] request.next_attempt = Ignore", self.worker);
                            continue;
                        }
                    };

                    let _ = task.request_completed(response).await;
                    if task.get_request().get_next_attempt() != &request::RequestType::Ignore {
                        self.task_dispatcher.add_task(task);
                    }
                    sleep(Duration::from_secs_f32(self.task_buffer)).await
                }
                None => {
                    debug!("[worker={}] No task", self.worker);
                    sleep(Duration::from_secs_f32(self.no_task_sleep)).await
                }
            }
        }
    }

    async fn execute_webarchive_requests(
        &self,
        request: &request::Request,
    ) -> errors::RequestResult {
        let archive_request = request.build_archive_request()?;
        let archive_response = self
            .execute_basic_request(archive_request)
            .await?
            .body_bytes()
            .await?;
        let wayback_json: serde_json::Value = serde_json::from_slice(&archive_response)?;
        let archive_url = wayback_json["archived_snapshots"]["closest"]["url"]
            .as_str()
            .ok_or(errors::RequestError::OptionNoneError)?;
        let archive_request = request.build_request(archive_url.parse::<hyper::Uri>().unwrap());
        let response = self.execute_basic_request(archive_request).await?;
        Ok(response)
    }

    async fn execute_basic_request(
        &self,
        hyper_request: hyper::Request<hyper::Body>,
    ) -> errors::RequestResult {
        debug!(
            "[worker={}] Basic request to {}",
            self.worker,
            hyper_request.uri().to_string()
        );
        let resp = self.client.request(hyper_request).await?;
        let request_response = request::RequestResponse::new(resp);
        Ok(request_response)
    }

    async fn execute_request(&self, request: &request::Request) -> errors::RequestResult {
        let hyper_request = request.build_standard_request();
        let mut resp = self.client.request(hyper_request).await?;

        // Handles redirects
        let headers = resp.headers();
        if request.get_allow_redirect() == true && headers.contains_key(hyper::header::LOCATION) {
            let redirect_url = headers
                .get(hyper::header::LOCATION)
                .ok_or(errors::RequestError::NoRedirect)?
                .to_str()?;
            let redirect_uri = redirect_url.parse::<hyper::Uri>()?;
            let redirect_request = request.build_request(redirect_uri);
            resp = self.client.request(redirect_request).await?;
        }

        let request_response = request::RequestResponse::new(resp);
        Ok(request_response)
    }
}
